{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqcgPtx4HwrFbBI6sy7oTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arthaAgastya/Image-Classification-with-CNN-using-Keras/blob/main/Image_Classification_with_CNN_using_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image-Classification-with-CNN-using-Keras"
      ],
      "metadata": {
        "id": "3y0xvrqIWWBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Preparation: We start by loading the CIFAR-10 dataset, which contains 50,000 training images and 10,000 test images. Each image belongs to one of the ten classes. The dataset is divided into training and test sets, allowing us to evaluate the performance of our trained model accurately."
      ],
      "metadata": {
        "id": "4B3yEBJDWf2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "lWo-ACmMW1ew"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the Data: \n",
        "Before feeding the images into our model, we perform preprocessing steps to ensure optimal training performance. We normalize the pixel values of the images to a range between 0 and 1, transforming the images from integer format to floating-point values. Then we split training data into training and validation set into 80% and 20% repectively. "
      ],
      "metadata": {
        "id": "LeULIxeRWf98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "V4c-ThWMW5GK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture: We define a CNN model using the Sequential API provided by Keras. The model consists of convolutional layers, pooling layers, and fully connected layers. We use activation functions such as ReLU (Rectified Linear Unit) and softmax to introduce non-linearity and enable multi-class classification."
      ],
      "metadata": {
        "id": "MSoelVrbWgGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "AWnc6aAPYpOI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Compilation: Before training, we compile the model by specifying the optimizer, loss function, and evaluation metric. We use the Adam optimizer, which is widely used for training deep learning models. For multi-class classification, we employ the sparse categorical cross-entropy loss function. The accuracy metric is used to evaluate the model's performance during training."
      ],
      "metadata": {
        "id": "oCEX8R9yWgWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iuRzSCLcYs1h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training: We train the model using the fit() method, passing in the training data, labels, number of epochs, and validation data. The model iteratively adjusts its parameters to minimize the loss and improve its predictive performance. During training, we monitor the validation accuracy to track the model's progress."
      ],
      "metadata": {
        "id": "G32sM2O9Wga0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuEQ4BRjYvEy",
        "outputId": "261002d1-b59d-4e68-9d3b-a53a6973d614"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 14s 5ms/step - loss: 1.6090 - accuracy: 0.4079 - val_loss: 1.3218 - val_accuracy: 0.5267\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2683 - accuracy: 0.5481 - val_loss: 1.1656 - val_accuracy: 0.5918\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1065 - accuracy: 0.6089 - val_loss: 1.0565 - val_accuracy: 0.6312\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9869 - accuracy: 0.6541 - val_loss: 0.9820 - val_accuracy: 0.6504\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.8968 - accuracy: 0.6858 - val_loss: 0.9555 - val_accuracy: 0.6662\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.8274 - accuracy: 0.7106 - val_loss: 0.9562 - val_accuracy: 0.6736\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.7653 - accuracy: 0.7326 - val_loss: 0.9225 - val_accuracy: 0.6839\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7149 - accuracy: 0.7505 - val_loss: 0.9108 - val_accuracy: 0.6926\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6682 - accuracy: 0.7660 - val_loss: 0.9136 - val_accuracy: 0.6996\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6268 - accuracy: 0.7782 - val_loss: 0.9154 - val_accuracy: 0.6968\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feef18e3d60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation: After training, we evaluate the model's performance on the test set using the classification_report() method. The classification_report function calculates and displays various metrics, including precision, recall, F1-score, and support, for each class in the classification problem. It provides valuable insights into the performance of the model for each class, allowing you to assess its accuracy, sensitivity, and specificity."
      ],
      "metadata": {
        "id": "bx0_x9heWgds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation set\n",
        "predictions = model.predict(X_val)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_val, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgUEtPHBaSKn",
        "outputId": "63d98ac5-0222-4e73-d44e-a9dcb76b2241"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.75      0.71       973\n",
            "           1       0.80      0.83      0.81       979\n",
            "           2       0.55      0.64      0.59      1030\n",
            "           3       0.58      0.39      0.47      1023\n",
            "           4       0.69      0.60      0.64       933\n",
            "           5       0.59      0.65      0.62      1015\n",
            "           6       0.73      0.79      0.76       996\n",
            "           7       0.83      0.69      0.75       994\n",
            "           8       0.74      0.86      0.79      1017\n",
            "           9       0.81      0.77      0.79      1040\n",
            "\n",
            "    accuracy                           0.70     10000\n",
            "   macro avg       0.70      0.70      0.69     10000\n",
            "weighted avg       0.70      0.70      0.69     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLK8lLk4YyEU",
        "outputId": "166152dd-e1b1-443f-fef4-e8c4da94d5ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.87      0.48      1000\n",
            "           1       0.69      0.65      0.67      1000\n",
            "           2       0.78      0.10      0.19      1000\n",
            "           3       0.35      0.14      0.20      1000\n",
            "           4       0.72      0.11      0.19      1000\n",
            "           5       0.41      0.57      0.47      1000\n",
            "           6       0.86      0.28      0.42      1000\n",
            "           7       0.62      0.65      0.63      1000\n",
            "           8       0.47      0.58      0.52      1000\n",
            "           9       0.45      0.78      0.57      1000\n",
            "\n",
            "    accuracy                           0.47     10000\n",
            "   macro avg       0.57      0.47      0.43     10000\n",
            "weighted avg       0.57      0.47      0.43     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0UEqHyYZrNS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}